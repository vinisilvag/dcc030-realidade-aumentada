{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df6d0ed",
   "metadata": {},
   "source": [
    "# TP2 - Realidade Aumentada\n",
    "\n",
    "__Aluno:__ Vinicius Silva Gomes\n",
    "\n",
    "__Matrícula:__ 2021421869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1145329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Importa as bibliotecas necessárias para o programa\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from math import atan, pi\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from objloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258554c8",
   "metadata": {},
   "source": [
    "## Extraindo frames do vídeo para calibração\n",
    "\n",
    "Esse pequeno script foi feito para extrair os frames do vídeo e usá-los para calibrar a câmera e obter os parâmetros intrínsecos da câmera. O script, em suma, carrega o vídeo, usando o OpenCV, e salva cada frame no disco, em uma pasta chamada ./fames.\n",
    "\n",
    "Dessa pasta, foram escolhidos 6 frames que apresentavam angulações, distâncias e rotações diferentes do tabuleiro xadrez e esses frames foram separados para serem usados na calibração da câmera. Esses frames escolhidos foram: __frame0.jpg, frame161.jpg, frame260.jpg, frame411.jpg, frame702.jpg, frame800.jpg__. \n",
    "\n",
    "__OBS: Para que as imagens sejam salvas, a pasta ./frames precisa ter sido criada previamente.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5645462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai os frames do vídeo para realizar a calibração da câmera\n",
    "\n",
    "cam = cv2.VideoCapture(\"./entrada.mp4\")\n",
    "\n",
    "current_frame = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if ret:\n",
    "        # Para esse trecho funcionar uma pasta ./frames deve existir no diretório do notebook\n",
    "        name = './frames/frame' + str(current_frame) + '.jpg'\n",
    "  \n",
    "        cv2.imwrite(name, frame)\n",
    "  \n",
    "        current_frame += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5825d",
   "metadata": {},
   "source": [
    "## Obtendo os parâmetros intrínsecos e os coeficientes de distorção\n",
    "\n",
    "Com os frames selecionados, foi usado o MatLAB para obter os parâmetros intrísecos da câmera. A opção \"Camera Calibration\" foi a escolhida. Os pontos do tabuleiro foram selecionados e após o mapeamento e as devidas funções internas do MatLAB terem sido executadas, a matriz de parâmetros intrínsecos foi obtida. Além disso, a partir dessa calibração os coeficientes de distorção também puderam ser obtidos.\n",
    "\n",
    "A próxima célula apresenta a declaração dessa matriz com os dados de output do MatLAB.\n",
    "\n",
    "<!-- OBS: A matriz foi transposta para se parecer com a matriz que foi estudada e usada como exemplo ao longo das aulas da disciplina. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5e30ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[412.53052313   0.         315.18267262]\n",
      " [  0.         409.20049776 225.06795532]\n",
      " [  0.           0.           1.        ]]\n",
      "[ 0.11205172 -0.25125965  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Matriz com os parâmetros intrínsecos da câmera\n",
    "intrinsic_params = np.array(([412.530523133597, 0, 315.182672617247],\n",
    "                             [0, 409.200497755689, 225.067955320591],\n",
    "                             [0, 0, 1]))\n",
    "\n",
    "# Vetor com os coeficientes de distorção obtidos na calibração\n",
    "distortion_coefficients = np.array([0.112051723551952, -0.251259653193207, 0, 0])\n",
    "\n",
    "print(intrinsic_params)\n",
    "print(distortion_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b321054",
   "metadata": {},
   "source": [
    "## Localizando os alvos ao longo do vídeo\n",
    "\n",
    "As funções a seguir são responsáveis por localizar os alvos ao longo de um frame. O vídeo será executado e cada frame será passado como parâmetro para as funções para que os alvos sejam localizados nele e retornados de maneira adequada para serem exibidos pelo OpenGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe8814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(target, template):\n",
    "    target_normalized = (target - target.mean()) / np.std(target)\n",
    "    template_normalized = (template - template.mean()) / np.std(template)\n",
    "    \n",
    "    return np.mean(target_normalized * template_normalized)\n",
    "\n",
    "# Dado o possível alvo retificado, calcula sua semelhança com todas as possíveis rotações do\n",
    "# template e retorna, primeiramente, se o possível alvo é de fato um alvo e qual a sua orientação, caso seja.\n",
    "def find_orientation(rectified, template):\n",
    "    # Rotaciona o template nas direções possíveis\n",
    "    left = cv2.rotate(template.copy(), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    up = template.copy()\n",
    "    right = cv2.rotate(template.copy(), cv2.ROTATE_90_CLOCKWISE)\n",
    "    down = cv2.rotate(template.copy(), cv2.ROTATE_180)\n",
    "    \n",
    "    # Calcula o erro para cada uma delas\n",
    "    err_up = normalized_cross_correlation(rectified, up)\n",
    "    err_right = normalized_cross_correlation(rectified, right)    \n",
    "    err_down = normalized_cross_correlation(rectified, down)\n",
    "    err_left = normalized_cross_correlation(rectified, left)\n",
    "    \n",
    "    errors = [err_up, err_right, err_down, err_left]\n",
    "    \n",
    "    # Identifica o menor erro obtido\n",
    "    min_error = max(errors)\n",
    "    min_index = errors.index(min_error)\n",
    "    \n",
    "    # Caso o erro esteja no limiar estabelecido, o alvo foi identificado e terá sua orientação retornada\n",
    "    # 0 -> cima, 1 -> direita, 2 -> baixo, 3 -> esquerda\n",
    "    if min_error > 0.7 and min_error < 1:\n",
    "        return True, min_index\n",
    "    else:\n",
    "        return False, -1\n",
    "\n",
    "# Dado o frame com um possível alvo e as coordenadas do alvo, retifica a imagem para saber se é um alvo ou não \n",
    "def compare_target(thresh, target, copy):\n",
    "    template = cv2.imread(\"./alvo.jpg\", 0)\n",
    "    \n",
    "    # Cria a matriz com os pontos do template\n",
    "    template_points = np.array([[0, 0],\n",
    "                            [template.shape[0], 0],\n",
    "                            [template.shape[0], template.shape[1]],\n",
    "                            [0, template.shape[1]]])\n",
    "    \n",
    "    # Calcula a homografia do possível alvo em relação a matriz dos pontos do template\n",
    "    homography, _ = cv2.findHomography(target, template_points, cv2.RANSAC)\n",
    "    \n",
    "    # Retifica o alvo com a matriz de homografia\n",
    "    rectified = cv2.warpPerspective(thresh, homography, (template.shape[0], template.shape[1]))\n",
    "    \n",
    "    # Obtém se ele é um alvo e qual a orientação dele, caso seja\n",
    "    is_target, orientation = find_orientation(rectified, template)\n",
    "        \n",
    "    return is_target, orientation\n",
    "    \n",
    "# Função principal que usa todas as outras para identificar os alvos em cada frame\n",
    "def identify_targets(frame):\n",
    "    copy = frame.copy()\n",
    "    # Converte o frame para escala de tons de cinza\n",
    "    gray_frame = cv2.cvtColor(copy, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # Calcula a binarização do frame\n",
    "    _, thresh = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "    # Enfatiza as bordas presentes no frame binarizado\n",
    "    edged = cv2.Canny(thresh, 100, 200)\n",
    "    \n",
    "    # Cria os contornos ao longo das bordas do frame\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    targets = []\n",
    "\n",
    "    # Para cada contorno identificado\n",
    "    for contour in contours:\n",
    "        # Aproxima sua forma geométrica para obter o número de lados\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.015 * perimeter, True)\n",
    "        no_vertices = len(approx)\n",
    "        \n",
    "        # Caso o contorno identificado tenha 4 lados\n",
    "        if no_vertices == 4:\n",
    "            # Verifica se ele é um alvo\n",
    "            is_target, orientation = compare_target(thresh, approx, copy)\n",
    "                        \n",
    "            # Caso seja um alvo, insere no vetor de alvos identificados naquele frame\n",
    "            if is_target:\n",
    "                targets.append(approx)\n",
    "                \n",
    "    # Desenha de verde os contornos identificados no frame\n",
    "    cv2.drawContours(copy, targets, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Retorna o frame contornado e os alvos identificados nesse frame\n",
    "    return copy, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e58c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25777/1969284090.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  target_normalized = (target - target.mean()) / np.std(target)\n"
     ]
    }
   ],
   "source": [
    "### DEBUG\n",
    "video = cv2.VideoCapture(\"./entrada.mp4\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(count < 10):\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame, targets = identify_targets(frame)\n",
    "                \n",
    "        # plt.imshow(frame, cmap='gray')\n",
    "        # plt.show()\n",
    "                \n",
    "        count += 1\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee94c79-9cf6-4933-9a28-929a0f3f311a",
   "metadata": {},
   "source": [
    "## Funções da OpenGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915ac2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    " def initOpenGL(intrinsic_params, dimensions):\n",
    "    (width, height) = dimensions\n",
    "    \n",
    "    glClearColor(0.0, 0.0, 0.0, 0.0)\n",
    "    glClearDepth(1.0)\n",
    "\n",
    "    glEnable(GL_DEPTH_TEST)\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    fx = intrinsic_params[0, 0];\n",
    "    fy = intrinsic_params[1, 1];\n",
    "    \n",
    "    fovy = 2 * atan(0.5 * height/fy) * 180/pi;\n",
    "    aspect = (width * fy)/(height * fx);\n",
    "    near = 0.1;\n",
    "    far = 200.0;\n",
    "    \n",
    "    gluPerspective(fovy, aspect, near, far);\n",
    "    \n",
    "def load_background(frame):\n",
    "    background_id = glGenTextures(1)\n",
    "    glBindTexture(GL_TEXTURE_2D, background_id)\n",
    "    \n",
    "    background = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    background = cv2.flip(background, 0)\n",
    "    \n",
    "    height, width, channels = background.shape\n",
    "    background = np.frombuffer(background.tobytes(), dtype=background.dtype, count = height * width * channels)    \n",
    "    background.shape = (height, width, channels)\n",
    "\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, background)\n",
    "    \n",
    "    return background_id, background\n",
    "    \n",
    "def place_background(frame, dimensions):\n",
    "    background_id, background = load_background(frame)\n",
    "    \n",
    "    (width, height) = dimensions\n",
    "    \n",
    "    glDepthMask(GL_FALSE)\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPushMatrix()\n",
    "    glLoadIdentity()\n",
    "    gluOrtho2D(0, width, 0, height)\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glBindTexture(GL_TEXTURE_2D, background_id)\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, 3, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, background)\n",
    "    glPushMatrix()\n",
    "\n",
    "    glBegin(GL_QUADS)\n",
    "    glTexCoord2i(0, 0); glVertex2i(0, 0)\n",
    "    glTexCoord2i(1, 0); glVertex2i(width, 0)\n",
    "    glTexCoord2i(1, 1); glVertex2i(width, height)\n",
    "    glTexCoord2i(0, 1); glVertex2i(0, height)\n",
    "    glEnd()\n",
    "    \n",
    "    glPopMatrix()\n",
    "\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glPopMatrix()\n",
    "\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glDepthMask(GL_TRUE)\n",
    "    glDisable(GL_TEXTURE_2D)\n",
    "    \n",
    "def calculate_projection_matrix(target, intrinsic_params, distortion_coefficients):\n",
    "    object_points = np.array([[0, 0, 0], [1, 0, 0],\n",
    "                              [0, 1, 0], [1, 1, 0]], dtype=\"float32\")\n",
    "    \n",
    "    image_points = target[:, 0].astype(\"float32\")\n",
    "            \n",
    "    _, rotation_vec, translation_vec = cv2.solvePnP(object_points, image_points, intrinsic_params, distortion_coefficients)\n",
    " \n",
    "    rotation_matrix = cv2.Rodrigues(rotation_vec)[0]\n",
    "    \n",
    "    projection_matrix = np.array([[rotation_matrix[0, 0], rotation_matrix[0, 1], rotation_matrix[0, 2], translation_vec[0]],\n",
    "                                [rotation_matrix[1, 0], rotation_matrix[1, 1], rotation_matrix[1, 2], translation_vec[1]],\n",
    "                                [rotation_matrix[2, 0], rotation_matrix[2, 1], rotation_matrix[2, 2], translation_vec[2]],\n",
    "                                [0, 0, 0, 1]], dtype=\"float32\")\n",
    "    \n",
    "    flip_yz_matrix = np.array([[1,  0,  0, 0],\n",
    "                               [0, -1,  0, 0],\n",
    "                               [0,  0, -1, 0],\n",
    "                               [0,  0,  0, 1]])\n",
    "    \n",
    "    projection_matrix = flip_yz_matrix @ projection_matrix\n",
    "    \n",
    "    return projection_matrix.T\n",
    "        \n",
    "def object3D(obj, projection_matrix):\n",
    "    # Carrega a matriz de projeção no OpenGL\n",
    "    glMatrixMode(GL_PROJECTION)\n",
    "    glLoadMatrixd(projection_matrix)\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    \n",
    "    # Renderiza o modelo do Pikachu\n",
    "    glCallList(obj.gl_list)\n",
    "\n",
    "    # Renderiza um cubo ao redor do Pikachu\n",
    "    glutWireCube(2.0)\n",
    "\n",
    "    \n",
    "def displayCallback():\n",
    "    glMatrixMode(GL_MODELVIEW)\n",
    "    glLoadIdentity()\n",
    "    \n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    glEnable(GL_TEXTURE_2D)\n",
    "\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame_with_contour, targets = identify_targets(frame)\n",
    "        place_background(frame_with_contour, (640, 480))\n",
    "        \n",
    "#         for target in targets:\n",
    "#             projection_matrix = calculate_projection_matrix(target, intrinsic_params, distortion_coefficients)\n",
    "        \n",
    "#             obj = OBJ(\"Pikachu.obj\", swapyz=True)\n",
    "#             object3D(obj, projection_matrix)\n",
    "\n",
    "        glutSwapBuffers()\n",
    "\n",
    "def idleCallback():\n",
    "    glutPostRedisplay()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464b3d3-11f6-4896-b257-ef78c0070326",
   "metadata": {},
   "source": [
    "## OpenGL Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee205f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25777/1969284090.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  target_normalized = (target - target.mean()) / np.std(target)\n"
     ]
    }
   ],
   "source": [
    "dimensions = (640, 480)\n",
    "\n",
    "# Parâmetros intrínsecos e coeficientes de distorção obtidos com a calibração\n",
    "intrinsic_params = np.array(([412.530523133597, 0, 315.182672617247],\n",
    "                             [0, 409.200497755689, 225.067955320591],\n",
    "                             [0, 0, 1]))\n",
    "\n",
    "distortion_coefficients = np.array([0.112051723551952, -0.251259653193207, 0, 0])\n",
    "\n",
    "# Carrega o vídeo da pasta\n",
    "video = cv2.VideoCapture(\"./entrada.mp4\")\n",
    "\n",
    "# Inicializa a glut\n",
    "glutInit()\n",
    "glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)\n",
    "glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_CONTINUE_EXECUTION)\n",
    "\n",
    "glutInitWindowSize(*dimensions)\n",
    "\n",
    "# Cria a janela e inicializa o OpenGL com os parâmetros da câmera e as dimensões da janela\n",
    "window = glutCreateWindow(b'TP2 - Realidade Aumentada - Vinicius Silva Gomes')\n",
    "initOpenGL(intrinsic_params, dimensions)\n",
    "\n",
    "# Chama as funções principais de display e entra no loop principal do OpenGL\n",
    "glutDisplayFunc(displayCallback)\n",
    "glutIdleFunc(idleCallback)\n",
    "\n",
    "glutMainLoop()\n",
    "\n",
    "# Desaloca o vídeo de entrada\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53564a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
